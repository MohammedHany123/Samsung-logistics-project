{
  "metadata": {
    "name": "Project",
    "kernelspec": {
      "language": "scala",
      "name": "spark2-scala"
    },
    "language_info": {
      "codemirror_mode": "text/x-scala",
      "file_extension": ".scala",
      "mimetype": "text/x-scala",
      "name": "scala",
      "pygments_lexer": "scala"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2,
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark.pyspark\nfrom pyspark.sql import SparkSession\nfrom pyspark.sql.functions import *\nfrom pyspark.sql.functions import col, to_date, datediff, when\nfrom pyspark.sql.functions import sum as _sum, round, countDistinct\n\nspark \u003d SparkSession.builder.appName(\"ETL\").enableHiveSupport().getOrCreate()"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark.pyspark\n\n# Load data and assign column names\n\nlogistics_df \u003d spark.read.csv(\"/staging_zone/logistics/logistics_data\", header\u003dFalse, inferSchema\u003dTrue) \\\n    .toDF(\"logistics_id\", \"order_id\", \"estimated_delivery_date\", \"actual_delivery_date\", \"shipping_cost\", \"warehouse_id\")\n\norder_lines \u003d spark.read.csv(\"/staging_zone/staging_orderlines/staging_order_lines_data\", header\u003dFalse, inferSchema\u003dTrue) \\\n    .toDF(\"order_id\", \"product_id\", \"quantity\", \"price\")"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark.pyspark\n# Inspect schema and sample data for logistics\n\nlogistics_df.printSchema()\nlogistics_df.show(5)"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark.pyspark\n# Inspect schema and sample data for order lines\n\norder_lines.printSchema()\norder_lines.show(5)"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark.pyspark\n\n# Clean and transform logistics dates: \n\nlogistics_df \u003d logistics_df.filter(col(\"estimated_delivery_date\").isNotNull() \u0026 col(\"actual_delivery_date\").isNotNull()) \\\n    .withColumn(\"estimated_delivery_date\", to_date(col(\"estimated_delivery_date\"), \"yyyy-MM-dd\")) \\\n    .withColumn(\"actual_delivery_date\", to_date(col(\"actual_delivery_date\"), \"yyyy-MM-dd\"))"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark.pyspark\n\n# Create logistics fact table:\n\nlogistics_fact \u003d logistics_df \\\n    .withColumn(\"delivery_time_delta_days\", datediff(col(\"actual_delivery_date\") ,col(\"estimated_delivery_date\"))) \\\n    .withColumn(\"is_late_delivery\", when(col(\"delivery_time_delta_days\") \u003e 0, 1).otherwise(0)) \\\n    .select(\"order_id\", \"delivery_time_delta_days\", \"is_late_delivery\", \"shipping_cost\", \"warehouse_id\")\n    \nlogistics_fact.show(10)"
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark.pyspark\n# Join logistics fact with order lines to get revenue\n\nlogistics_fact_joined \u003d logistics_fact.join(order_lines, on\u003d\"order_id\", how\u003d\"inner\") \\\n                        .withColumn(\"total_revenue\",round(col(\"quantity\") * col(\"price\"), 2))\n                        \nlogistics_fact_joined.show(10)"
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark.pyspark\n# Check if an order is served by multiple warehouses\n\norder_warehouse_check \u003d logistics_fact.groupBy(\"order_id\") \\\n                        .agg(countDistinct(\"warehouse_id\").alias(\"warehouse_count\")) \\\n                        .withColumn(\"is_multi_warehouse\", when(col(\"warehouse_count\") \u003e 1, 1).otherwise(0)) \\\n                        .filter(col(\"warehouse_count\") \u003e 1) \n                        \norder_warehouse_check.show()"
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark.pyspark\n\n# Aggregate order-level summary:\n\norder_summary \u003d logistics_fact_joined.groupBy(\"order_id\", \"warehouse_id\", \"is_late_delivery\", \"shipping_cost\") \\\n    .agg(round(sum(\"total_revenue\"), 2).alias(\"total_revenue_per_order\")) \\\n    .orderBy(\"order_id\")\n\norder_summary.show(10)"
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark.pyspark\n\n# Aggregate warehouse-level summary:\n\nwarehouse_summary \u003d order_summary.groupBy(\"warehouse_id\") \\\n    .agg(\n        round(_sum(\"total_revenue_per_order\"), 2).alias(\"total_revenue\"),\n        round(_sum(\"shipping_cost\"), 2).alias(\"total_shipping_cost\"),\n        sum(\"is_late_delivery\").alias(\"late_deliveries\"),\n        countDistinct(\"order_id\").alias(\"total_orders\")) \\\n    .withColumn(\"late_delivery_rate\", round((col(\"late_deliveries\") / col(\"total_orders\")) * 100, 2)) \\\n    .withColumn(\"avg_shipping_cost_per_order\", round(col(\"total_shipping_cost\") / col(\"total_orders\"), 2)) \\\n    .orderBy(\"warehouse_id\")\n\nwarehouse_summary.show(10)"
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark.pyspark\n\n# Warehouse efficiency analysis: calculate ratio of shipping cost to total revenue\n\nwarehouse_eff \u003d warehouse_summary.withColumn(\"shipping_to_revenue_ratio\",\n            round(col(\"total_shipping_cost\") / col(\"total_revenue\"), 3)) \\\n            .select(\"warehouse_id\", \"shipping_to_revenue_ratio\")\n\nwarehouse_eff.show()"
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark.pyspark\n\n# Delivery performance per warehouse: average delivery delay in days\n\ndelivery_perf \u003d logistics_fact.groupBy(\"warehouse_id\") \\\n    .agg(round(avg(\"delivery_time_delta_days\"), 2).alias(\"avg_delivery_time_delta\")) \\\n    .orderBy(\"warehouse_id\")\n\ndelivery_perf.show()"
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark.pyspark\n\n# Product-level analysis of late deliveries:\n\nproduct_delay \u003d logistics_fact_joined.groupBy(\"product_id\") \\\n    .agg(sum(\"is_late_delivery\").alias(\"late_deliveries\"),\n         countDistinct(\"order_id\").alias(\"total_orders\")) \\\n    .withColumn(\"late_rate\", round(col(\"late_deliveries\") / col(\"total_orders\") * 100, 2)) \\\n    .orderBy(desc(\"late_rate\"))\n\nproduct_delay.show(10)"
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark.pyspark\n\n# Save Fact Table\nlogistics_fact.write.mode(\"overwrite\").parquet(\"/staging_zone/staging_logistics_fact\")\n\n# Save Order Summary\norder_summary.write.mode(\"overwrite\").parquet(\"/staging_zone/order_summary\")\n\n# Save Warehouse Summary\nwarehouse_summary.write.mode(\"overwrite\").parquet(\"/staging_zone/warehouse_summary\")\n\n# Save Product Delay\nproduct_delay.write.mode(\"overwrite\").parquet(\"/staging_zone/product_delay_summary\")"
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark.pyspark\n# Register Temp Views for Spark SQL queries\n\nlogistics_fact.createOrReplaceTempView(\"logistics_fact\")\norder_summary.createOrReplaceTempView(\"order_summary\")\nwarehouse_summary.createOrReplaceTempView(\"warehouse_summary\")\nproduct_delay.createOrReplaceTempView(\"product_delay_summary\")"
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark.sql\n-- Spark SQL Query: Calculate average delivery time delta (days) per warehouse\n\nSELECT warehouse_id,\n    ROUND(AVG(delivery_time_delta_days), 2) AS avg_delivery_time_delta\nFROM logistics_fact\nGROUP BY warehouse_id\nORDER BY warehouse_id;"
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark.sql\n\n-- Top warehouses with highest late delivery rate\n\nSELECT warehouse_id, late_delivery_rate\nFROM warehouse_summary\nORDER BY late_delivery_rate DESC;"
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark.sql\n\n-- Top 10 products causing delays\n\nSELECT product_id, late_rate, late_deliveries, total_orders\nFROM product_delay_summary\nORDER BY late_rate DESC\nLIMIT 10;"
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark.sql\n\n-- Revenue vs shipping cost ratio per warehouse\n\nSELECT warehouse_id,\n       total_revenue,\n       total_shipping_cost,\n       ROUND(total_shipping_cost/total_revenue,3) AS shipping_to_revenue_ratio\nFROM warehouse_summary\nORDER BY shipping_to_revenue_ratio DESC;"
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark.sql\n\n-- Warehouse efficiency vs late deliveries\n\nSELECT \n    warehouse_id,\n    COUNT(order_id) AS total_orders,\n    SUM(is_late_delivery) AS late_deliveries,\n    ROUND(SUM(total_revenue_per_order), 2) AS total_revenue,\n    ROUND(SUM(shipping_cost), 2) AS total_shipping_cost,\n    ROUND(SUM(total_revenue_per_order)/SUM(shipping_cost), 2) AS revenue_to_shipping_ratio,\n    ROUND(SUM(is_late_delivery)/COUNT(order_id)*100, 2) AS late_delivery_rate_percentage\nFROM order_summary\nGROUP BY warehouse_id\nORDER BY revenue_to_shipping_ratio DESC, late_delivery_rate_percentage ASC;"
    }
  ]
}
